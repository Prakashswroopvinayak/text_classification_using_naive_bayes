{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize   # sent_tokenize to tokenize sentences\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=datasets.fetch_20newsgroups()     # Fetch data from datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=text.data    # X Data\n",
    "y=text.target  # Y Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2]  # Raw Input data Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y data \n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data\n",
    "x_train=x[:8000]\n",
    "x_test=x[8000:]\n",
    "y_train=y[:8000]\n",
    "y_test=y[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features name\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature names\n",
    "print(\"Features name\\n\")\n",
    "target_names=text.target_names\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Stopwords that are not usefull for training thats why i will remove stop word from data\n",
    "stopword = { 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone',\n",
    "             'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount',\n",
    "             'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around',\n",
    "             'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before',\n",
    "             'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
    "             'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de',\n",
    "             'describe', 'detail', 'did', 'do', 'does', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg',\n",
    "             'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone',\n",
    "             'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for',\n",
    "             'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had',\n",
    "             'has', 'hasnt', 'have', 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "             'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less',\n",
    "             'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
    "             'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine',\n",
    "             'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once',\n",
    "             'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
    "             'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 's'\n",
    "             'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', \n",
    "             'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system',\n",
    "             't', 'take', 'ten', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
    "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this',\n",
    "             'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward',\n",
    "             'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we',\n",
    "             'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
    "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom',\n",
    "             'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
    "             'yourselves'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  nltk provide stop word \n",
    "p=stopwords.words(\"english\")\n",
    "len(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update our stopword with nltk stopwords\n",
    "stopword.update(p)\n",
    "len(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making list conting punctuation  and update with stopwords\n",
    "punctuations=list(string.punctuation)\n",
    "stopword.update(punctuations)\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final length of stopwords\n",
    "len(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of punction and number , we remove all the words which strat withh pun\n",
    "pun=['!', '\"', '#','$', '%', '&', \"'\",'(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<','=','>', '?','@','[', '\\\\', ']','^', '_', '`','{','|', '}', '~','0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it remove words that start with punction and number\n",
    "def startwith(pun,word):\n",
    "    count=0\n",
    "    for i in pun:\n",
    "        if  word.startswith(i):\n",
    "            return 0\n",
    "        elif i in word:\n",
    "            return 0\n",
    "    return 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary word as a keys \n",
    "dic={}\n",
    "for file in x:       \n",
    "    words=word_tokenize(file)      # it tokenize all text into words\n",
    "    for word in words:\n",
    "        if len(word)>=3:             # it check word length \n",
    "            p=startwith(pun,word)         # check word start with punction or number and return 0 or 1\n",
    "            if (not word.lower()  in stopword ) and p:   # word not in stopwords\n",
    "                if word in dic:\n",
    "                    dic[word]+=1\n",
    "                else:\n",
    "                    dic[word]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lerxst': 2,\n",
       " 'thing': 1479,\n",
       " 'Subject': 11741,\n",
       " 'car': 1176,\n",
       " 'Organization': 10945,\n",
       " 'University': 5442,\n",
       " 'Maryland': 122,\n",
       " 'College': 528,\n",
       " 'Park': 146,\n",
       " 'Lines': 11353}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(dic.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict={}                             #this is the reverse sorted form of dictionary used above\n",
    "for key,value in sorted(dic.items(),key=lambda item: item[1],reverse=True):\n",
    "    new_dict[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject': 11741,\n",
       " 'Lines': 11353,\n",
       " 'Organization': 10945,\n",
       " 'writes': 7838,\n",
       " 'article': 6681,\n",
       " 'people': 5632,\n",
       " 'like': 5545,\n",
       " 'University': 5442,\n",
       " 'know': 5043,\n",
       " 'MAX': 4450}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(new_dict.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=new_dict.values()   # get all values of new_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12327"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it gives number of words occur more than 15 times\n",
    "c=0\n",
    "for i in p:\n",
    "    if i>=15:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Length\t 12327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Subject',\n",
       " 'Lines',\n",
       " 'Organization',\n",
       " 'writes',\n",
       " 'article',\n",
       " 'people',\n",
       " 'like',\n",
       " 'University',\n",
       " 'know',\n",
       " 'MAX',\n",
       " 'think',\n",
       " 'use',\n",
       " 'time',\n",
       " 'good',\n",
       " 'way',\n",
       " 'see',\n",
       " 'make',\n",
       " 'say',\n",
       " 'Distribution',\n",
       " 'God']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=list(new_dict.keys())[:c]  \n",
    "print(\"Feature Length\\t\",len(features))\n",
    "features[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train data\n",
    "x_train_dataset=np.zeros((len(x_train),len(features)))\n",
    "for i in range(len(x_train)):\n",
    "    for word in word_tokenize(x_train[i]):\n",
    "        if word in features:\n",
    "            x_train_dataset[i][features.index(word)]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_test_dataset=np.zeros((len(x_test),len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test(x_test,features):\n",
    "    for i in range(len(x_test)):\n",
    "        for word in word_tokenize(x_test[i]):\n",
    "            if word in features:  \n",
    "                x_test_dataset[i][features.index(word)]+=1\n",
    "    return x_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1=create_test(x_test,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_dataset,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9485, 0.8717561858780929)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuaccuracy_score on training  testing data\n",
    "clf.score(x_train_dataset,y_train),clf.score(x_test1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       146\n",
      "           1       0.72      0.83      0.77       167\n",
      "           2       0.90      0.69      0.78       176\n",
      "           3       0.67      0.77      0.72       166\n",
      "           4       0.76      0.88      0.81       155\n",
      "           5       0.88      0.81      0.85       159\n",
      "           6       0.76      0.79      0.78       174\n",
      "           7       0.92      0.89      0.90       184\n",
      "           8       0.90      0.92      0.91       164\n",
      "           9       0.95      0.93      0.94       164\n",
      "          10       0.96      0.97      0.97       183\n",
      "          11       0.96      0.94      0.95       173\n",
      "          12       0.78      0.83      0.80       166\n",
      "          13       0.97      0.89      0.93       168\n",
      "          14       0.96      0.94      0.95       198\n",
      "          15       0.87      0.92      0.89       175\n",
      "          16       0.91      0.96      0.93       162\n",
      "          17       0.96      0.96      0.96       163\n",
      "          18       0.93      0.86      0.90       150\n",
      "          19       0.87      0.68      0.76       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3314\n",
      "   macro avg       0.88      0.87      0.87      3314\n",
      "weighted avg       0.88      0.87      0.87      3314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[[132   0   0   0   0   0   0   0   0   0   0   1   0   0   1   8   0   0\n",
      "    0   4]\n",
      " [  0 139   4   6   5   5   7   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8 122  26   4  10   2   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   6   3 127  12   0   5   1   0   0   0   1  10   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   2   2  10 136   0   4   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  19   2   3   2 129   0   2   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   2   1   8   5   0 138   7   2   0   0   2   5   0   1   0   0   1\n",
      "    1   0]\n",
      " [  1   1   0   0   0   0   5 164   5   2   0   0   6   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   1   1   5   2 151   2   0   0   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   3   0   1 153   5   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   2 178   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   2   1   0   0   0   1   0   0   0   0 162   1   1   1   0   1   0\n",
      "    3   0]\n",
      " [  0   6   0   7   9   1   2   2   1   0   0   0 137   1   0   0   0   0\n",
      "    0   0]\n",
      " [  1   4   0   0   2   0   1   0   3   1   0   0   1 150   2   2   1   0\n",
      "    0   0]\n",
      " [  0   2   0   0   1   0   0   0   2   0   1   0   4   0 187   0   1   0\n",
      "    0   0]\n",
      " [  2   1   0   1   1   0   1   0   0   0   0   0   2   1   0 161   1   1\n",
      "    0   3]\n",
      " [  0   0   0   0   0   0   2   0   0   0   0   2   0   0   0   0 156   0\n",
      "    0   2]\n",
      " [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 156\n",
      "    3   1]\n",
      " [  3   0   0   0   0   0   3   1   1   1   1   1   0   1   0   0   4   3\n",
      "  129   2]\n",
      " [ 10   0   0   0   0   0   1   0   1   0   0   0   1   1   1  14   8   1\n",
      "    1  82]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tENTER SOMETHING\n",
      "\n",
      "The Citizenship Amendment Bill provides for citizenship of minority refugees from 3 neighboring countries, opposing it in the northeastern states The citizenship bill passed in the Lok Sabha in the previous term of the Modi government. Apart from this, the Union Cabinet also approved the proposal to extend SC / ST reservation in the legislature for 10 years. The Union Cabinet on Wednesday approved the Citizenship Amendment Bill, 2019. This will facilitate the granting of Indian citizenship to non-Muslims (Hindus, Sikhs, Jains, Buddhists, Parsis, and Christians) from Afghanistan, Bangladesh, and Pakistan. The government can present the bill in Parliament in the winter session itself. The Modi government had passed the bill in the Lok Sabha in January this year during the previous term.  Opposition parties have criticized the Citizenship Bill as discriminatory on religious grounds. Assam and other northeastern states had raised objections to the bill and they held protest across cities. Understand the Citizenship Amendment Bill in Q&A…  1. WHEN DID CITIZENSHIP LAW COME AND WHAT IS IN IT? Answer: This law came in 1955. Under this, the Indian government grants citizenship to non-Muslims (Hindus, Sikhs, Jains, Buddhists, Parsis, and Christians) from Afghanistan, Bangladesh, and Pakistan after 12 years of stay in the country.  2. WHAT AMENDMENT IS THE GOVERNMENT GOING TO MAKE? Answer: The amended Bill provides for a period of 6 years for minority refugees from Afghanistan, Bangladesh, and Pakistan to get citizenship. Non-Muslims will get citizenship even if there is no valid document. Also, all those who came before 31 December 2014 will get citizenship.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\tENTER SOMETHING\\n\")\n",
    "inp=input().split(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert user data into input format\n",
    "test_data=np.zeros((1,len(features)))\n",
    "\n",
    "for word in inp:\n",
    "    if word in features:\n",
    "        test_data[0][features.index(word)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data is of type  :\t talk.politics.mideast\n"
     ]
    }
   ],
   "source": [
    "own_pred=clf.predict(test_data)\n",
    "print(\"Your data is of type  :\\t\",target_names[own_pred[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
